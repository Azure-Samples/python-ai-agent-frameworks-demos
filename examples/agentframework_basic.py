import asyncio
import os

from agent_framework import ChatAgent
from agent_framework.openai import OpenAIChatClient
from azure.identity.aio import DefaultAzureCredential, get_bearer_token_provider
from dotenv import load_dotenv
from rich import print

# Configure OpenAI client based on environment
load_dotenv(override=True)
API_HOST = os.getenv("API_HOST", "github")

async_credential = None
if API_HOST == "azure":
    async_credential = DefaultAzureCredential()
    token_provider = get_bearer_token_provider(async_credential, "https://cognitiveservices.azure.com/.default")
    client = OpenAIChatClient(base_url=os.environ["AZURE_OPENAI_ENDPOINT"] + "/openai/v1/", api_key=token_provider, model_id=os.environ["AZURE_OPENAI_CHAT_DEPLOYMENT"])
elif API_HOST == "github":
    client = OpenAIChatClient(base_url="https://models.github.ai/inference", api_key=os.environ["GITHUB_TOKEN"], model_id=os.getenv("GITHUB_MODEL", "openai/gpt-4o"))
elif API_HOST == "ollama":
    client = OpenAIChatClient(base_url=os.environ.get("OLLAMA_ENDPOINT", "http://localhost:11434/v1"), api_key="none", model_id=os.environ.get("OLLAMA_MODEL", "llama3.1:latest"))
else:
    client = OpenAIChatClient(api_key=os.environ["OPENAI_API_KEY"], model_id=os.environ.get("OPENAI_MODEL", "gpt-4o"))

agent = ChatAgent(chat_client=client, instructions="You're an informational agent. Answer questions cheerfully.")


async def main():
    response = await agent.run("Whats weather today in San Francisco?")
    print(response.text)

    if async_credential is not None:
        await async_credential.close()


if __name__ == "__main__":
    asyncio.run(main())
